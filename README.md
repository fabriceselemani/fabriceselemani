<header>
<h1>Fabrice Selemani</h1>
<p class="highlight">Data Engineer | Portfolio still in development ðŸš§</p>
</header>

<main>
<section>
<h2>What I Do</h2>
<p>


Hi, Iâ€™m Fabrice Selemani, a passionate and forward-thinking Data Engineer dedicated to designing and building modern, scalable data infrastructure.



While this portfolio is still in active development, it already reflects the level of complexity and depth I bring to data engineering projects. Iâ€™m continuously expanding and refining my knowledge and tooling to stay at the forefront of the field.

I build production-grade data pipelines, manage real-time data streams, and architect cloud-native data ecosystems.
</p>
<ul>
<li>ETL/ELT pipelines using Apache Airflow in Docker containers</li>
<li>Real-time ingestion with Kafka and CDC via Debezium</li>
<li>Data warehouse automation using Snowflake + Snowpipe</li>
<li>Streaming analytics with Kafka Streams and PySpark</li>
<li>NoSQL experience with MongoDB and Cassandra</li>
<li>Monitoring with email notification, and Airflow alerting</li>
<li>CI/CD using GitHub Actions and Docker</li>
</ul>
</section>

<section>
<h2>Current Projects</h2>
<p><strong>Note:</strong> This portfolio is growing with me. These are real-world builds I'm actively working on:</p>
<ul>
<li>
<strong><a href="https://github.com/fabriceselemani/load_to_snowflake_from_s3_bucket.git" target="_blank">
load to snowflake from s3 bucket
</a></strong>: we extract data from the New York City API, process it, and load it into an S3 bucket. Then, we use the Snowflake COPY command to load the data into Snowflake tables.
</li>
<li>
<strong><a href="https://github.com/yourusername/cloud-lakehouse-pipeline" target="_blank">
Cloud Lakehouse Pipeline
</a></strong>: Ingesting data from AWS S3 to Snowflake via Snowpipe with star schema modeling.
</li>
<li>
<strong><a href="https://github.com/yourusername/automated-bi-platform" target="_blank">
Automated BI Platform
</a></strong>: SQL transformation + automated Tableau and Power BI dashboard refresh with Airflow.
</li>
</ul>
</section>

<section>
<h2>Technologies</h2>
<table>
<thead>
<tr>
<th>Category</th>
<th>Tools / Platforms</th>
</tr>
</thead>
<tbody>
<tr>
<td>Cloud</td>
<td>AWS (S3, EC2, Lambda, Glue), Snowflake</td>
</tr>
<tr>
<td>Orchestration</td>
<td>Apache Airflow, Docker</td>
</tr>
<tr>
<td>Streaming</td>
<td>Apache Kafka, Kafka Streams, Debezium</td>
</tr>
<tr>
<td>Batch</td>
<td>PySpark, Pandas, SQL</td>
</tr>
<tr>
<td>Databases</td>
<td>PostgreSQL, MySQL, MongoDB, Cassandra, snowflake</td>
</tr>
<tr>
<td>Data Viz</td>
<td>Power BI</td>
</tr>
<tr>
<td>Monitoring</td>
<td>Email notification, Airflow Alerts</td>
</tr>
<tr>
<td>CI/CD</td>
<td>GitHub Actions, Docker, Kubernetes (coming soon)</td>
</tr>
</tbody>
</table>
</section>

<section>
<h2>Where Iâ€™m Headed</h2>
<ul>
<li>Kubernetes end-to-end deployment</li>
<li>Event-driven microservices with Protobuf</li>
<li>Observability with OpenTelemetry</li>
<li>CI/CD with Helm and ArgoCD</li>
</ul>
</section>

<section>
<h2>Letâ€™s Connect</h2>
<p>If you're looking for a data engineer who builds scalable, modern pipelines and never stops learning; reach out below:</p>
<ul>
<li>Email: <a href="fabrices1996@gmail.com">fabrices1996@gmail.com</a></li>
<li>LinkedIn: <a href="https://linkedin.com/in/yourprofile" target="_blank">linkedin.com/in/yourprofile</a></li>
<li>GitHub: <a href="https://github.com/yourgithub" target="_blank">github.com/yourgithub</a></li>
</ul>
</section>
</main>

<footer>
<p>Â© 2025 Fabrice Selemani â€” Data Engineering Portfolio</p>
</footer>

</body>
</html>
